This document, titled "Generative & Agentic AI - 22 July - Notes by Gemini," summarizes a session led by AI Council on August 7, 2025, concerning GPT and prompt engineering.

Key topics covered include:

  * **GPT and Prompt Engineering Introduction:** AI Council initiated the session by outlining the use of GPT for text generation with Python and exploring prompt engineering techniques, with the ultimate goal of creating a RAG (Retrieval Augmented Generation) application using GPT.
  * **OpenAI Library Installation and API Key Setup:** The session detailed the process of installing the OpenAI library using `PIP install OpenAI`, accessing API keys from openai.com, and securely storing them as Colab secrets to prevent exposure.
  * **Basic API Usage and Response Handling:** AI Council demonstrated the fundamental use of the OpenAI API, including importing the `OpenAI` class, creating a client object, and using `client.responses.create` to generate output, specifying parameters like model, instructions, and prompt.
  * **Simple Prompting Techniques (Zero-Shot Prompting):** The concept of "simple prompting" or "zero-shot prompting" was introduced, where tasks are given directly without examples. It was shown how to define a `messages` variable with `role` and `content` for summarizing text, emphasizing its suitability for large-scale applications.
  * **Role-Based Prompting:** This technique involves assigning a "system" role to define the model's persona (e.g., "customer support agent," "helpful assistant") for tailored responses. The `temperature` parameter was also discussed for controlling creativity (recommended values between 0.7 and 0.8).
  * **One-Shot and Few-Shot Prompting:** "One-shot prompting" involves providing a single example of desired behavior to guide the model's output, while "few-shot prompting" uses multiple examples, particularly useful for tasks like sentiment analysis.
  * **Chain of Thought Prompting:** This technique encourages the model to "think step by step," providing a detailed reasoning process along with the final answer, which helps in logical deduction.
  * **Role-Playing Prompting and Output Formatting:** AI Council showcased how assigning a specific persona (e.g., "pirate," "frustrated employee") influences the model's response style. Additionally, they demonstrated how to request output in specific formats like JSON or Markdown.
  * **Prompting for LLM Models:** The session emphasized that prompting is a crucial skill for optimizing results from any Large Language Model (LLM). Various techniques like zero-shot, one-shot, few-shot, role-based, and chain of thought prompting were reviewed.
  * **Using GPT in Python:** The process of integrating GPT into Python was detailed, including library installation, secure API key definition, and using `client.chat.completions.create` to define 'user', 'assistant', and 'system' roles for controlled interactions.
  * **Souvik Roy's Inquiry:** Souvik Roy specifically inquired about the necessity of defining both 'system' and 'user' roles, to which AI Council clarified that while a 'user' role suffices for generic outputs, a 'system' role is vital for directing the model's behavior as an expert or researcher.

# -*- coding: utf-8 -*-
"""genai_3_diffusion_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WNPXxxhusGAmbW9q0Iydo6vh-oP5zAoT

**Step 1 - Library Installation**
"""

!pip install diffusers transformers

"""**Step 2 - Load the pretained diffusion models**"""

from diffusers import StableDiffusionPipeline
import torch

model_id = "sd-legacy/stable-diffusion-v1-5"
pipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)
pipe = pipe.to("cuda")

"""**Step 3 - Text-to-Image Generation**"""

#prompt = "a photo of an astronaut riding a horse on mars"
prompt = "a photo of a boy having coffee at starbucks"
image = pipe(prompt).images[0]

image.save("coffee_boy.png")

"""**Step 4 - Visualise the image**"""

import cv2
import matplotlib.pyplot as plt

image_read = cv2.imread('/content/coffee_boy.png')
image_read = cv2.cvtColor(image_read , cv2.COLOR_BGR2RGB)

plt.imshow(image_read)
plt.show()

"""**Step 5 - Build a web based Image generator**"""

import gradio as gr

def generate_image(prompt):
  image = pipe(prompt).images[0]
  return image

gr.Interface(fn = generate_image, inputs = "text" , outputs="image" , title="Image Generator").launch()

from diffusers import DiffusionPipeline
import torch

pipe = DiffusionPipeline.from_pretrained("stabilityai/stable-diffusion-xl-base-1.0", torch_dtype=torch.float16, use_safetensors=True, variant="fp16")
pipe.to("cuda")

# if using torch < 2.0
# pipe.enable_xformers_memory_efficient_attention()

prompt = "a photo of a boy having coffee at starbucks"

images = pipe(prompt=prompt).images[0]
images.save("coffee_boy.png")

import cv2
import matplotlib.pyplot as plt

image_read = cv2.imread('/content/coffee_boy.png')
image_read = cv2.cvtColor(image_read , cv2.COLOR_BGR2RGB)

plt.imshow(image_read)
plt.show()

"""**Access gated Repository**"""

from huggingface_hub import notebook_login
notebook_login()

import torch
from diffusers import FluxPipeline

pipe = FluxPipeline.from_pretrained("black-forest-labs/FLUX.1-dev", torch_dtype=torch.bfloat16)
pipe.enable_model_cpu_offload() #save some VRAM by offloading the model to CPU. Remove this if you have enough GPU power
#pipe.to("cuda")

prompt = "A cat holding a sign that says hello world"
image = pipe(
    prompt,
    height=1024,
    width=1024,
    guidance_scale=3.5,
    num_inference_steps=50,
    max_sequence_length=512,
    generator=torch.Generator("cpu").manual_seed(0)
).images[0]
image.save("flux-dev.png")

"""**Qwen**"""

!pip install git+https://github.com/huggingface/diffusers

from diffusers import DiffusionPipeline
import torch

model_name = "Qwen/Qwen-Image"

# Load the pipeline
if torch.cuda.is_available():
    torch_dtype = torch.bfloat16
    device = "cuda"
else:
    torch_dtype = torch.float32
    device = "cpu"

pipe = DiffusionPipeline.from_pretrained(model_name, torch_dtype=torch_dtype)
pipe = pipe.to(device)

positive_magic = {
    "en": "Ultra HD, 4K, cinematic composition." # for english prompt
}

"""**Step 6 - Generate image with Qwen model**"""

prompt = "a photo of a boy having coffee at starbucks"

# You can use the positive_magic dictionary to add magic words to your prompt.
# For example, if your prompt is in English:
# prompt = prompt + positive_magic["en"]

image = pipe(prompt=prompt).images[0]
image.save("qwen_coffee_boy.png")

# Generate image
prompt = '''A coffee shop entrance features a chalkboard sign reading "Qwen Coffee 😊 $2 per cup," with a neon light beside it displaying "通义千问". Next to it hangs a poster showing a beautiful Chinese woman, and beneath the poster is written "π≈3.1415926-53589793-23846264-33832795-02384197". Ultra HD, 4K, cinematic composition'''

negative_prompt = " " # using an empty string if you do not have specific concept to remove


# Generate with different aspect ratios
aspect_ratios = {
    "1:1": (1328, 1328),
    "16:9": (1664, 928),
    "9:16": (928, 1664),
    "4:3": (1472, 1140),
    "3:4": (1140, 1472),
    "3:2": (1584, 1056),
    "2:3": (1056, 1584),
}

width, height = aspect_ratios["16:9"]

image = pipe(
    prompt=prompt + positive_magic["en"],
    negative_prompt=negative_prompt,
    width=width,
    height=height,
    num_inference_steps=50,
    true_cfg_scale=4.0,
    generator=torch.Generator(device="cuda").manual_seed(42)
).images[0]

image.save("example.png")